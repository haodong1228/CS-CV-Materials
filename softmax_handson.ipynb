{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"softmax_handson.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dTC4iCLP0sVG","colab_type":"text"},"source":["# ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã€€(softmax regression)ã®å®Ÿè£…\n","# ç›®æ¬¡\n","1. æ¦‚è¦\n","- ç›®æ¨™\n","- ä¸‹æº–å‚™\n","- softmaxé–¢æ•°ã®å®Ÿè£…\n","- å¤šã‚¯ãƒ©ã‚¹äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã®å®Ÿè£…\n","- ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã‚¯ãƒ©ã‚¹ã®å®Ÿè£…\n","- å­¦ç¿’\n","\n","# 1. æ¦‚è¦\n","- ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®ä¸€èˆ¬åŒ–ã§ï¼Œå¤šã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã—ãŸæ‰‹æ³•\n","- Kå€‹ã®ã‚¯ãƒ©ã‚¹è­˜åˆ¥å•é¡Œã‚’è€ƒãˆã‚‹ï¼$\\boldsymbol{x}$ï¼šå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼Œ$\\boldsymbol{t}$ï¼šæ•™å¸«ãƒ‡ãƒ¼ã‚¿\n","\n","\\begin{align}\n","\\it{D}=\\left\\{\\left(\\boldsymbol{x}_i,\\boldsymbol{t}_i\\right)\\right\\}_{i=1}^{N}\\, ,\\boldsymbol{x}\\in\\mathbb{R}^d,\\, \\boldsymbol{t}\\in\\left\\{1,\\cdots,K\\right\\}\n","\\end{align}\n","\n","- å„ã‚¯ãƒ©ã‚¹ã®äº‹å¾Œç¢ºç‡ã‚’æ±‚ã‚ã‚‹ï¼å„ã‚¯ãƒ©ã‚¹ã”ã¨ã«é‡ã¿è¡Œåˆ— $\\boldsymbol{w}^{(ğ‘—)}$ã‚’æŒã¤ï¼\n","$$\n","P(y=1|\\,\\boldsymbol{x})=\\frac{\\exp({\\boldsymbol{w}^{(1)\\top}\\boldsymbol{x}})}{\\sum_{j=1}^{K}\\exp{(\\boldsymbol{w}^{(j)\\top}\\boldsymbol{x}})}\\\\\n","P(y=2|\\,\\boldsymbol{x})=\\frac{\\exp({\\boldsymbol{w}^{(2)\\top}\\boldsymbol{x}})}{\\sum_{j=1}^{K}\\exp{(\\boldsymbol{w}^{(j)\\top}\\boldsymbol{x}})}\\\\\n","\\vdots\\\\\n","P(y=K|\\,\\boldsymbol{x})=\\frac{\\exp({\\boldsymbol{w}^{(K)\\top}\\boldsymbol{x}})}{\\sum_{j=1}^{K}\\exp{(\\boldsymbol{w}^{(j)\\top}\\boldsymbol{x}})}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"76H1sytv0sVI","colab_type":"text"},"source":["# 2. ç›®æ¨™\n","- ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã‚’å®Ÿè£…ã—ã¦ï¼Œmnistï¼ˆæ‰‹æ›¸ãæ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã‚’è­˜åˆ¥ã™ã‚‹ï¼\n","- ã¾ãš**æ´»æ€§åŒ–é–¢æ•°**ã®ä¸€ç¨®ã§ã‚ã‚‹**softmax**é–¢æ•°ã¨ï¼Œ**äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é–¢æ•°**ã‚’å®Ÿè£…ã™ã‚‹ï¼ãã®å¾Œç¢ºç‡**çš„å‹¾é…é™ä¸‹æ³•**ã‚’å®Ÿè£…ã—ï¼Œ**SoftmaxRegression**ã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…ã™ã‚‹ï¼"]},{"cell_type":"markdown","metadata":{"id":"AwatT0oB0sVJ","colab_type":"text"},"source":["# 3. ä¸‹æº–å‚™\n","## 3.1 ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n","- matplotlib: å›³ã‚„ã‚°ãƒ©ãƒ•ã®æç”»ãªã©ï¼\n","- numpy: è¡Œåˆ—æ¼”ç®—ãªã©\n","- sklearn: scikit-learnï¼æ§˜ã€…ãªæ©Ÿæ¢°å­¦ç¿’ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã‚‹ãŒï¼Œä»Šå›ã¯MNISTã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã«ç”¨ã„ã‚‹ï¼"]},{"cell_type":"code","metadata":{"id":"PRi2I9olK7T1","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from __future__ import print_function"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBn555zkVXAO","colab_type":"code","colab":{}},"source":["from google.colab import drive # driveã‚’æ¥ç¶š\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gHPHdZLVfT4","colab_type":"code","colab":{}},"source":["# driveä¸­ã®èª²é¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•\n","%cd /content/gdrive/My Drive/handson20200512/\n","\n","from test_softmax import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RPI09MhY0sVQ","colab_type":"text"},"source":["## 3.2 MNISTãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n","- ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ï¼ä¸€åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ï¼Œãã®å¾Œã¯ãƒ‡ãƒ¼ã‚¿ã‚’å‚ç…§ã—ã¦èª­ã¿è¾¼ã‚“ã§ãã‚Œã‚‹ã®ã§ï¼Œæ¯å›ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãªãã¦ã‚‚è‰¯ããªã‚‹ï¼\n","- XãŒç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ŒYãŒæ­£è§£ãƒ‡ãƒ¼ã‚¿\n","- mnistã®ãƒ‡ãƒ¼ã‚¿ã¯ï¼Œ0~255ã®intå‹ã§è¡¨ã•ã‚Œã¦ã„ã‚‹ãŒï¼Œã“ã‚Œã‚’**255ã§å‰²ã£ã¦**æ­£è¦åŒ–ã™ã‚‹ï¼"]},{"cell_type":"code","metadata":{"id":"_VFl1sNe0sVR","colab_type":"code","colab":{}},"source":["X, Y = fetch_openml('mnist_784', version=1, data_home=\".\", return_X_y=True)\n","X = X / 255.\n","Y = Y.astype(\"int\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U4WlHWs10sVT","colab_type":"text"},"source":["### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯è¦–åŒ–"]},{"cell_type":"code","metadata":{"id":"SFtmq1PO0sVU","colab_type":"code","colab":{}},"source":["for i in range(10):\n","    plt.subplot(2, 5, i + 1)\n","    plt.imshow(X[i * 6500].reshape(28, 28), cmap='gray_r')\n","    plt.axis(\"off\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W-zZtlXz0sVW","colab_type":"text"},"source":["### å­¦ç¿’ç”¨ãƒ»ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n","- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ï¼ŒåŒã˜è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½ã®è©•ä¾¡ã‚’è¡Œã†ã¨ï¼Œè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã¯è‰¯ã„æ€§èƒ½ã‚’ç¤ºã™ãŒï¼Œãƒ‡ãƒ¼ã‚¿ã‚’å°‘ã—ã§ã‚‚å¤‰ãˆã‚‹ã¨æ€§èƒ½ãŒä½ä¸‹ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚‹ï¼ˆ**éå­¦ç¿’**ï¼‰ï¼\n","- ã‚ˆã£ã¦ï¼Œå­¦ç¿’ã™ã‚‹è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã¯ç•°ãªã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½è©•ä¾¡ã‚’è¡Œã†ï¼"]},{"cell_type":"code","metadata":{"id":"yNEB4-H60sVX","colab_type":"code","colab":{}},"source":["train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=2)\n","train_y = np.eye(10)[train_y].astype(np.int32)\n","test_y = np.eye(10)[test_y].astype(np.int32)\n","train_n = train_x.shape[0]\n","test_n = test_x.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkr-Eal00sVb","colab_type":"text"},"source":["# 4. softmaxé–¢æ•°ã®å®Ÿè£…\n","æ´»æ€§åŒ–é–¢æ•°ã®ä¸€ç¨®ã§ã‚ã‚‹softmaxé–¢æ•°ã‚’å®Ÿè£…ã™ã‚‹ï¼\n","- é–¢æ•°ï¼šsoftmax\n","    - å…¥åŠ›ï¼š$\\boldsymbol{X}=(\\boldsymbol{x}_1,\\boldsymbol{x}_2,\\cdots,\\boldsymbol{x}_N)^\\top\\in\\mathbb{R}^{N\\times K}$\n","    - å‡ºåŠ›ï¼š$\\boldsymbol{Y}=(\\boldsymbol{y}_1,\\boldsymbol{y}_2,\\cdots,\\boldsymbol{y}_N)^\\top\\in\\mathbb{R}^{N\\times K},\\,\\,\\,y_{nk} = softmax(\\boldsymbol{x}_n)_k$\n","    - ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ããŸã‚ã«$\\boldsymbol{x}_n$ã®æœ€å¤§å€¤ã‚’$\\boldsymbol{x}_n$è‡ªèº«ã‹ã‚‰å¼•ã\n","$$\n","\\begin{align}\n","softmax(\\boldsymbol{x})_k&= \\frac{\\exp (x_{k})} {\\Sigma_{i=1}^{K}{\\exp (x_{i})}}\\\\\n","&=\\frac{\\exp (-x_{max})\\exp (x_{k})}{\\exp (-x_{max})\\Sigma_{i=1}^{K}{\\exp (x_{i})}}=\\frac{\\exp (x_{k}-x_{max})} {\\Sigma_{i=1}^{K}{\\exp (x_{i}-x_{max})}}\n","\\end{align}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"1zrpt_q00sVc","colab_type":"text"},"source":["<details>\n","<summary>\n","ãƒ’ãƒ³ãƒˆ\n","</summary>\n","<ol>\n","    <li>æœ€å¤§å€¤\n","    <ul> \n","        <li>```axis=1```ã‚’æŒ‡å®šã™ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿$\\boldsymbol{x_n}$ã”ã¨ã«æœ€å¤§å€¤ã‚’è¨ˆç®—ã§ãã‚‹</li>\n","        <li>è¡Œåˆ—ã®shapeã‚’å¤‰ãˆãŸããªã„å ´åˆã¯ï¼Œ```keepdims=True```ã‚’æŒ‡å®šã™ã‚‹</li>\n","    </ul></li>\n","    <li>$\\exp$\n","    <ul>\n","    <li>```np.exp()```</li>\n","    </ul></li>\n","    <li>åˆè¨ˆ\n","    <ul>\n","    <li>```np.sum()```</li>\n","    <li>```axis=1```ã‚’æŒ‡å®šã™ã‚‹ã¨ãƒ‡ãƒ¼ã‚¿$\\boldsymbol{x_n}$ã”ã¨ã«åˆè¨ˆã‚’è¨ˆç®—ã§ãã‚‹</li>\n","    <li>è¡Œåˆ—ã®shapeã‚’å¤‰ãˆãŸããªã„å ´åˆã¯ï¼Œ```keepdims=True```ã‚’æŒ‡å®šã™ã‚‹</li>\n","    </ul></li>\n","</ol>\n","</details>"]},{"cell_type":"code","metadata":{"id":"FbcZVE610sVc","colab_type":"code","colab":{}},"source":["def softmax(x):\n","    # TODO\n","    y = \n","    # TODO\n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-vUNsC50sVg","colab_type":"text"},"source":["ãƒ†ã‚¹ãƒˆï¼ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"]},{"cell_type":"code","metadata":{"id":"aZ5nQ-Se0sVg","colab_type":"code","colab":{}},"source":["test_softmax(softmax)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2NRmZt70sVj","colab_type":"text"},"source":["# 5. å¤šã‚¯ãƒ©ã‚¹ã®äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã®å®Ÿè£…\n","- é–¢æ•°ï¼šcross_entropy\n","    - å…¥åŠ›ï¼š $Y=(\\boldsymbol{y}_1,\\boldsymbol{y}_2,\\cdots,\\boldsymbol{y}_N)^\\top\\in \\mathbb{R}^{N\\times K}$, \n","$T=(\\boldsymbol{t}_1,\\boldsymbol{t}_2,\\cdots,\\boldsymbol{t}_N)^\\top\\in \\mathbb{R}^{N\\times K}$<br />\n","$\\boldsymbol{y}_n$ã¯ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°ã®å‡ºåŠ›ï¼Œ$\\boldsymbol{t}_n$ã¯æ•™å¸«ãƒ©ãƒ™ãƒ«(1-of-Kè¡¨ç¾)\n","\n","    - å‡ºåŠ›ï¼š \n","    $$L=-\\frac{1}{N}\\sum_{n=1}^N \\sum_i \\boldsymbol t_{n,i} \\log \\boldsymbol y_{n,i}\\in\\mathbb{R}^1\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"ERm53VeX0sVk","colab_type":"text"},"source":["<details>\n","<summary>\n","ãƒ’ãƒ³ãƒˆ\n","</summary>\n","<ol>\n","    <li>$\\log$\n","    <ul> \n","        <li>```np.log()```</li>\n","    </ul></li>\n","    <li>åˆè¨ˆ\n","    <ul>\n","    <li>```np.sum()```</li>\n","    </ul></li>\n","    <li>å¹³å‡\n","    <ul>\n","    <li>```np.mean()```</li>\n","    </ul></li>\n","</ol>\n","</details>"]},{"cell_type":"code","metadata":{"id":"ObGdYiNQ0sVl","colab_type":"code","colab":{}},"source":["def cross_entropy(y, t):\n","    # TODO\n","    L = \n","    # TODO\n","    return L"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWvg50d10sVo","colab_type":"text"},"source":["ãƒ†ã‚¹ãƒˆï¼ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"]},{"cell_type":"code","metadata":{"id":"HXiQGpZL0sVp","colab_type":"code","colab":{}},"source":["test_cross_entropy(cross_entropy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fsq6sAK40sVr","colab_type":"text"},"source":["# 6. ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã®å®Ÿè£…\n","ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…ã™ã‚‹ï¼\n","## 6.1 å‹¾é…é™ä¸‹æ³•ã®å®Ÿè£…\n","SoftmaxRegressionã‚¯ãƒ©ã‚¹ã®gradient_decenté–¢æ•°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ï¼\n","- é–¢æ•°ï¼šgradient_descent  \n","    - å…¥åŠ›ï¼š\n","        - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼š $\\boldsymbol{X}\\in\\mathbb{R}^{N\\times D}$\n","        - äºˆæ¸¬ãƒ©ãƒ™ãƒ«ï¼š$\\boldsymbol{Y}\\in\\mathbb{R}^{N\\times K}$\n","        - æ•™å¸«ãƒ©ãƒ™ãƒ«ï¼š$\\boldsymbol{T}\\in\\mathbb{R}^{N\\times K}$\n","        - å­¦ç¿’ç‡ï¼š$\\epsilon \\in \\mathbb{R}$\n","    - æ›´æ–°ï¼š\n","        - é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ $\\boldsymbol{W},\\,\\boldsymbol{b}$\n","        \n","- å‹¾é…é™ä¸‹æ³•: ï¼ˆ$\\boldsymbol{W},\\boldsymbol{b}$ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼Œ$\\epsilon$ï¼šå­¦ç¿’ç‡ï¼‰\n","$$\n","\\boldsymbol{W}\\leftarrow\\boldsymbol{W}-\\epsilon\\nabla_{\\boldsymbol{W}}L\\\\\n","\\boldsymbol{b}\\leftarrow\\boldsymbol{b}-\\epsilon\\nabla_{\\boldsymbol{b}}L\n","$$\n","- ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹å›å¸°ã®å‹¾é… :\n","\\begin{align}\n","\\nabla_{\\boldsymbol{W}}L&=\\frac{1}{N}\\boldsymbol{X}^\\top(\\boldsymbol{Y}-\\boldsymbol{T})\\\\\n","\\nabla_{\\boldsymbol{b}}L&=\\frac{1}{N}(1,1,...,1)(\\boldsymbol{Y}-\\boldsymbol{T})\n","\\end{align}"]},{"cell_type":"markdown","metadata":{"id":"aPfu71cu0sVs","colab_type":"text"},"source":["<details>\n","<summary>\n","ãƒ’ãƒ³ãƒˆ\n","</summary>\n","<ol>\n","    <li>è¡Œåˆ—ã®ç©\n","    <ul> \n","        <li>```np.dot()```</li>\n","    </ul></li>\n","    <li>åˆè¨ˆ\n","    <ul>\n","    <li>```np.sum()```</li>\n","    </ul></li>\n","</ol>\n","</details>"]},{"cell_type":"code","metadata":{"id":"zWPjvYq90sVt","colab_type":"code","colab":{}},"source":["class SoftmaxRegression:\n","    def __init__(self, n_in, n_out):\n","        self.W = np.random.uniform(0.08, -0.08, (n_in, n_out)) #å‹¾é…ã®åˆæœŸåŒ–\n","        self.b = np.zeros(n_out) #ãƒã‚¤ã‚¢ã‚¹ã®åˆæœŸåŒ–\n","        \n","    def gradient_decent(self, X, Y, T, eps):\n","        batchsize = X.shape[0]\n","        # TODO\n","        self.W = \n","        self.b = \n","        # TODO\n","        \n","    def train(self, x, t, lr):\n","        y = softmax(np.dot(x, self.W) + self.b) #äºˆæ¸¬\n","        self.gradient_decent(x, y, t, lr) #ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°\n","        loss = cross_entropy(y, t) #ãƒ­ã‚¹ã®ç®—å‡º\n","        return y, loss\n","\n","    def test(self, x, t):\n","        y = softmax(np.dot(x, self.W) + self.b) #äºˆæ¸¬\n","        loss = cross_entropy(y, t) #ãƒ­ã‚¹ã®ç®—å‡º\n","        return y, loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_rNHRNX0sVv","colab_type":"text"},"source":["ãƒ†ã‚¹ãƒˆï¼ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œ"]},{"cell_type":"code","metadata":{"id":"kdwl9LAo0sVw","colab_type":"code","colab":{}},"source":["test_gradient_decent(SoftmaxRegression)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mcwr-bmQ0sV0","colab_type":"text"},"source":["# 7. å­¦ç¿’\n","## 7.1 ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n","å…¥åŠ›ã¯784æ¬¡å…ƒï¼Œå‡ºåŠ›ã¯10æ¬¡å…ƒ"]},{"cell_type":"code","metadata":{"id":"q1c4NKEb0sV0","colab_type":"code","colab":{}},"source":["model = SoftmaxRegression(784, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yKwwvm4k0sV3","colab_type":"text"},"source":["## 7.2 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š\n","- å­¦ç¿’epochæ•°ã¯20\n","    - epochæ•°ã¨ã¯ï¼Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½•å›å­¦ç¿’ã™ã‚‹ã‹ã‚’è¡¨ã™æ•°ã§ã‚ã‚‹ï¼\n","- ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯100\n","    - ãƒŸãƒ‹ãƒãƒƒãƒã¨ã¯å°‘æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ãªã‚‹é›†åˆã§ã‚ã‚‹ï¼\n","- å­¦ç¿’ç‡ã¯1"]},{"cell_type":"code","metadata":{"id":"LUY-Z1s60sV4","colab_type":"code","colab":{}},"source":["n_epoch = 20\n","batchsize = 100\n","lr = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i7g0yf9n0sV6","colab_type":"text"},"source":["## 7.3 å­¦ç¿’\n","äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã‚’ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ã‚’ç”¨ã„ã¦æœ€å°åŒ–ã™ã‚‹ï¼"]},{"cell_type":"code","metadata":{"id":"3hoW6nbq0sV7","colab_type":"code","colab":{}},"source":["for epoch in range(n_epoch):\n","    print ('epoch %d |ã€€' % epoch, end=\"\")\n","    \n","    # Training\n","    sum_loss = 0\n","    pred_label = []\n","    perm = np.random.permutation(train_n) #ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã³æ›¿ãˆã‚‹\n","    \n","    for i in range(0, train_n, batchsize): #ãƒŸãƒ‹ãƒãƒƒãƒã”ã¨ã«å­¦ç¿’ã‚’è¡Œã†\n","        x = train_x[perm[i:i+batchsize]]\n","        y = train_y[perm[i:i+batchsize]]\n","        \n","        pred, loss = model.train(x, y, lr)\n","        sum_loss += loss * x.shape[0]\n","        # pred ã«ã¯ï¼Œ (N, 10)ã®å½¢ã§ï¼Œç”»åƒãŒ0~9ã®å„æ•°å­—ã®ã©ã‚Œã«åˆ†é¡ã•ã‚Œã‚‹ã‹ã®äº‹å¾Œç¢ºç‡ãŒå…¥ã£ã¦ã„ã‚‹\n","        # ãã“ã§ï¼Œæœ€ã‚‚å¤§ãã„å€¤ã‚’ã‚‚ã¤ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ï¼Œè­˜åˆ¥çµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹\n","        pred_label.extend(pred.argmax(axis=1))\n","\n","    loss = sum_loss / train_n\n","    # æ­£è§£ç‡\n","    accu = accuracy_score(pred_label, np.argmax(train_y[perm], axis=1))\n","    print('Train loss %.3f, accuracy %.4f |ã€€' %(loss, accu), end=\"\")\n","    \n","    \n","    # Testing\n","    sum_loss = 0\n","    pred_label = []\n","    \n","    for i in range(0, test_n, batchsize):\n","        x = test_x[i: i+batchsize]\n","        y = test_y[i: i+batchsize]\n","        \n","        pred, loss = model.test(x, y)\n","        sum_loss += loss * x.shape[0]\n","        pred_label.extend(pred.argmax(axis=1))\n","        \n","    loss = sum_loss / test_n\n","    \n","    accu = accuracy_score(pred_label, np.argmax(test_y, axis=1))\n","    print('Test loss %.3f, accuracy %.4f' %(loss, accu) )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUSJ15NA0sWB","colab_type":"text"},"source":["ãƒ†ã‚¹ãƒˆã®æ­£è§£ç‡ãŒ92%ç¨‹åº¦ã«ãªã‚‹ã¨æˆåŠŸã§ã™ï¼"]}]}